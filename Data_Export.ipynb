
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MH8AieuU8riW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_sZgdJTd9gom"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>postID</th>\n",
       "      <th>channel</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PO0000045185</td>\n",
       "      <td>Bất động sản Thiện Nhân</td>\n",
       "      <td>(Mã số: BT3289)\\n- Bán gấp lô đất, biệt thự có...</td>\n",
       "      <td>BT3289 - Flycam - HÀNG HÓT Bán đất và biệt thự...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PO0000045199</td>\n",
       "      <td>BĐS CẨM MỸ 1</td>\n",
       "      <td>Bán đất mặt tiền đương giải phóng ,giáp đường ...</td>\n",
       "      <td>Bán đất mặt tiền đương giải phóng ,giáp đường ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PO0000045182</td>\n",
       "      <td>clip đường phố</td>\n",
       "      <td>*************************************\\nCảm ơn ...</td>\n",
       "      <td>bán đất biển bình châu sát ql 55 dt  6x22 thổ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>PO0000045180</td>\n",
       "      <td>Đất Bà Rịa Vũng Tàu Giá rẻ phan Văn Hòa</td>\n",
       "      <td>rất thích hợp làm nghĩ dưỡng đầu tư sinh lời \\...</td>\n",
       "      <td>Bán nhà  mới xây giá 1t550tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>PO0000045183</td>\n",
       "      <td>Phạm Hữu Dư</td>\n",
       "      <td>Có 2 lô đất liền kề diện tích hơn 5200m2 có sẵ...</td>\n",
       "      <td>Bán đất vườn thổ cư 5238m2 giá mềm đẹp vuông v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        postID                                  channel  \\\n",
       "0           0  PO0000045185                  Bất động sản Thiện Nhân   \n",
       "1           1  PO0000045199                             BĐS CẨM MỸ 1   \n",
       "2           2  PO0000045182                           clip đường phố   \n",
       "3           3  PO0000045180  Đất Bà Rịa Vũng Tàu Giá rẻ phan Văn Hòa   \n",
       "4           4  PO0000045183                              Phạm Hữu Dư   \n",
       "\n",
       "                                             content  \\\n",
       "0  (Mã số: BT3289)\\n- Bán gấp lô đất, biệt thự có...   \n",
       "1  Bán đất mặt tiền đương giải phóng ,giáp đường ...   \n",
       "2  *************************************\\nCảm ơn ...   \n",
       "3  rất thích hợp làm nghĩ dưỡng đầu tư sinh lời \\...   \n",
       "4  Có 2 lô đất liền kề diện tích hơn 5200m2 có sẵ...   \n",
       "\n",
       "                                               title  \n",
       "0  BT3289 - Flycam - HÀNG HÓT Bán đất và biệt thự...  \n",
       "1  Bán đất mặt tiền đương giải phóng ,giáp đường ...  \n",
       "2  bán đất biển bình châu sát ql 55 dt  6x22 thổ ...  \n",
       "3                       Bán nhà  mới xây giá 1t550tr  \n",
       "4  Bán đất vườn thổ cư 5238m2 giá mềm đẹp vuông v...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/dataExport.csv\").dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hLPNU_fo2YZs"
   },
   "outputs": [],
   "source": [
    "path = 'D:\\Learning\\DataExport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RSJ-wXLmS8QP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = '. '.join(df.iloc[:,2:].melt()['value'].values).lower()\n",
    "open(path + 'real_estates.txt', 'w', encoding='utf-8').write(corpus)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WZ0fh3KSkM84"
   },
   "outputs": [],
   "source": [
    "with open(path + '/replace_with_2_spaces.txt', 'r', encoding='utf-8') as f:\n",
    "    text_need_replace = f.read()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zAtTr3B-XQsH"
   },
   "outputs": [],
   "source": [
    "#removing emojis\n",
    "import re\n",
    "def remove_emojis(string):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\" \n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', string)\n",
    "\n",
    "def remove_link(string):\n",
    "  return re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', string, flags=re.MULTILINE)\n",
    "\n",
    "def remove(string):\n",
    "  lis = ['*', '=', ',', '..', '-', '_', '/', '+', '^', '?', '<', '>', ';', '{', '}', '[', ']', '!', '|', '&', '$', '~', '`', ')', '(']\n",
    "  for i in lis:\n",
    "    string = string.replace(i, '')\n",
    "  return string\n",
    "\n",
    "def remove_space(string):\n",
    "  return \" \".join(string.split())\n",
    "\n",
    "def replace_with_2_space(text):\n",
    "    abbr_to_replace = [txt.split(' ', 1) for txt in text_need_replace.split('\\n')]\n",
    "    for line in abbr_to_replace:\n",
    "        old = line[0]\n",
    "        new = line[1]\n",
    "        text = text.replace(old, new)\n",
    "        text = text.replace(new, new)\n",
    "    return text\n",
    "\n",
    "def solve(string):\n",
    "  func = [remove_emojis, remove_link, remove, remove_space, replace_with_2_space]\n",
    "  for i in func:\n",
    "    string = i(string)\n",
    "  return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "23X52TXcZXIc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480607"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = solve(corpus)\n",
    "open(path+'real_estates_after.txt', 'w', encoding='utf-8').write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mYoEhy96K8l9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
      "Requirement already satisfied, skipping upgrade: click in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.36.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (0.13.2)\n",
      "Collecting regex (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/64/50bd649be859345498ca4e23aeb424e35d8cca926787eda661493e60e55b/regex-2021.8.28-cp37-cp37m-win32.whl (254kB)\n",
      "Installing collected packages: regex, nltk\n",
      "  Found existing installation: nltk 3.4.5\n",
      "    Uninstalling nltk-3.4.5:\n",
      "      Successfully uninstalled nltk-3.4.5\n",
      "Successfully installed nltk-3.6.2 regex-2021.8.28\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aXltNUXhJM5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting underthesea\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/76/265876cadbad09685ee4be1dbd91b0f5c709d1072de0d3bb64561aeb65de/underthesea-1.3.2-py3-none-any.whl (7.5MB)\n",
      "Requirement already satisfied: nltk in d:\\programdata\\anaconda3\\lib\\site-packages (3.6.2)\n",
      "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/74/7d28a915630619f06c1a0cdf3c3dddc1516ac9bc31cb4764cc3f6e8142d4/python_crfsuite-0.9.7-cp37-cp37m-win32.whl (128kB)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (0.13.2)\n",
      "Collecting transformers<=3.5.1,>=3.5.0 (from underthesea)\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "Collecting unidecode (from underthesea)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
      "Collecting seqeval (from underthesea)\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "Requirement already satisfied: requests in d:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (2.22.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (0.21.1)\n",
      "Collecting torch<=1.5.1,>=1.1.0 (from underthesea)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement torch<=1.5.1,>=1.1.0 (from underthesea) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)\n",
      "ERROR: No matching distribution found for torch<=1.5.1,>=1.1.0 (from underthesea)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install underthesea nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2UVJ6YsLGLld"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'underthesea'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-42838c36f8bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0munderthesea\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'punkt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'underthesea'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import string\n",
    "import re\n",
    "from underthesea import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE, Laplace, KneserNeyInterpolated, WittenBellInterpolated\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF8dVnFIJJGD"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(path + 'real_estates_after.txt', 'r', encoding='utf-8') as f:\n",
    "    real_estates_corpus = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFXndKidZdih"
   },
   "source": [
    "Tiếp theo là các bước tiền xử lí cơ bản để lấy đầu vào cho mô hình n-gram:\n",
    "\n",
    "- Tách đoạn văn ra thành từng câu nhỏ\n",
    "- Loại bỏ các dấu câu trong câu\n",
    "- Tách từ (tokenize) với mỗi câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6FSvk1YTPfM"
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    tokens = word_tokenize(sent)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [word.translate(table) for word in tokens]\n",
    "    tokens = [word for word in tokens if word] # remove empty\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRYLg0CLk9X1"
   },
   "outputs": [],
   "source": [
    "sent_corpus = sent_tokenize(corpus) # tách câu\n",
    "len(sent_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ep2CTu1JZPdg"
   },
   "outputs": [],
   "source": [
    "word_corpus = [tokenize(sent) for sent in sent_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBuf1SnjZIZH"
   },
   "outputs": [],
   "source": [
    "n = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0hjWwd6WHy_"
   },
   "outputs": [],
   "source": [
    "# tách theo n gram\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, word_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evEFR8jjWI4p"
   },
   "outputs": [],
   "source": [
    "vi_model = KneserNeyInterpolated(n) # tạo mô hình n-gram interpolation\n",
    "vi_model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmbve1lCWKwO"
   },
   "outputs": [],
   "source": [
    "def generate_sent(model, max_num_words, pre_words=[]):\n",
    "    content = pre_words\n",
    "    for i in range(max_num_words):\n",
    "        token = model.generate(1, text_seed=content[-(n - 1):])\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cA5IR7RPYC3X"
   },
   "outputs": [],
   "source": [
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_86Pu0icZyDi"
   },
   "outputs": [],
   "source": [
    "def recommend_real_estates_search(txt_input):\n",
    "#     txt_input = pipeline_preprocessing_corpus(txt_input)\n",
    "    tokens = word_tokenize(txt_input)\n",
    "    output_recommend = []\n",
    "    for i in range(1, 10):\n",
    "        output = generate_sent(vi_model, i, tokens.copy())\n",
    "        output_recommend.append(detokenize(output))\n",
    "    output_recommend = list(set(output_recommend)) \n",
    "    return '\\n'.join(output_recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RE0-FOi0Z5U8"
   },
   "outputs": [],
   "source": [
    "txt_input = input()\n",
    "print(recommend_real_estates_search(txt_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TE63jYfEs4oT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN3KSNYZHrp+At8KCmQ/idF",
   "name": "Data_Export.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
